# Generated from model/s:
# - E:\original\tmpnvdz6ru4.without_runtime_opt\model.ort
# - E:\qwen\model.with_runtime_opt.ort
ai.onnx;1;SimplifiedLayerNormalization
ai.onnx;13;Gather{"inputs": {"0": ["int64_t", "uint8_t"], "1": ["int64_t"]}},ReduceSum{"inputs": {"0": ["int64_t"]}},Sigmoid{"inputs": {"0": ["float"]}}
ai.onnx;14;Mul{"inputs": {"0": ["float"]}},Sub{"inputs": {"0": ["int64_t"]}}
ai.onnx;21;Cast{"inputs": {"0": ["MLFloat16", "float", "int64_t"]}, "outputs": {"0": ["MLFloat16", "float", "int32_t"]}},DequantizeLinear{"inputs": {"0": ["uint8_t"]}},Reshape,Shape
com.microsoft;1;GroupQueryAttention,MatMulNBits,SkipSimplifiedLayerNormalization
